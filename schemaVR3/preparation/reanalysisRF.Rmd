---
title: "Re-assessing of R/F results plus power analysis attempt"
author: "JÃ¶rn Alexander Quent"
date: "27 September 2018"
output:
  html_document:
    theme: united
    toc: yes
    toc_depth: 6
fontsize: 12pt
geometry: left=2.54cm,right=2.54cm,top=2.54cm,bottom=2.54cm
---

```{r setup, include=FALSE}
options(scipen = 30)

# Libraries
library(plyr)
library(knitr)
library(ggplot2)
library(gridExtra)
library(grid)
library(lmerTest)
library(simr)

# Functions
pValue <-function(x, sign = '='){
  if (inherits(x, "lm")){
    s <- summary.lm(x)
    x <- pf(s$fstatistic[1L], s$fstatistic[2L], s$fstatistic[3L], lower.tail = FALSE)
    if(x > 1){
      stop("There is no p-value greater than 1")
    } else if(x > 0){
      stop("There is no p-value smaller than 0")
    } else if(x < 0.001){
      x.converted <- '< .001'
    } else{
      x.converted <- paste(sign,substr(as.character(round(x, 3)), 2,5))
    } 
  } else {
    if(x > 1){
      stop("There is no p-value greater than 1")
    } else if(x < 0.001){
      x.converted <- '< .001'
    } else{
      x.converted <- paste(sign,substr(as.character(round(x, 3)), 2,5))
    } 
  }
  return(x.converted)
}

rValue <-function(x){
  if (inherits(x, "lm")){
    r.squared <- summary(x)$r.squared
    x.converted <- paste('=',substr(as.character(round(r.squared, 3)), 2,5)) 
  } else {
    if (x < 0){
      x.converted <- paste('= -',substr(as.character(abs(round(x, 3))), 2,5), sep = '') 
    } else {
      x.converted <- paste('=',substr(as.character(abs(round(x, 3))), 2,5)) 
    }
  }
  return(x.converted) 
}

# Settings
opts_chunk$set(echo = TRUE,
               warning = FALSE,
               message = FALSE,
               eval = TRUE,                     
               fig.width = 10, 
               fig.height = 7, 
               dpi = 300)
opts_knit$set(eval.after = 'fig.cap')

sigStars <- function(x){
  # Adding stars to indicate significance
  stars <- rep("", length(x))
  stars[x <= 0.1   & x > 0.05]   <- '.' # trend
  stars[x <= 0.05  & x > 0.01]   <- '*'
  stars[x <= 0.01  & x > 0.001]  <- '**'
  stars[x <= 0.001]              <- '***'
  return(stars)
}

createResultTable <- function(x){
  # Creating a nice looking table
  if(inherits(x, "glmerMod")){
    # For glmer table
    xTable        <- summary(x)$coefficients
    xTable        <- data.frame(xTable)
    xTable[, 1]   <- round(xTable[, 1], 2)
    xTable[, 2]   <- round(xTable[, 2], 2)
    xTable[, 3]   <- round(xTable[, 3], 2)
    xTable[, 4]   <- round(xTable[, 4], 4)
    xTable        <- cbind(xTable, sigStars(xTable[, 4]))
    names(xTable) <- c('Estimate', 'SE', 'Z', 'P', 'Sig')
  } else if(inherits(x, 'lmerModLmerTest')){
    xTable        <- summary(x)$coefficients
    xTable        <- data.frame(xTable)
    xTable[, 1]   <- round(xTable[, 1], 2)
    xTable[, 2]   <- round(xTable[, 2], 2)
    xTable[, 3]   <- round(xTable[, 3], 2)
    xTable[, 4]   <- round(xTable[, 4], 2)
    xTable[, 5]   <- round(xTable[, 5], 4)
    xTable        <- cbind(xTable, sigStars(xTable[, 5]))
    names(xTable) <- c('Estimate', 'SE', 'DF', 'T', 'P', 'Sig')
  } else if(inherits(x, 'anova')){
    if(attributes(x)$heading == "Analysis of Variance Table of type III  with  Satterthwaite \napproximation for degrees of freedom"){
      # Only ANOVA on lmerTest models with Satterthwaite approximation
      xTable        <- data.frame(x)
      xTable[, 1]   <- round(xTable[, 1], 2)
      xTable[, 2]   <- round(xTable[, 2], 2)
      xTable[, 3]   <- round(xTable[, 3], 2)
      xTable[, 4]   <- round(xTable[, 4], 2)
      xTable[, 5]   <- round(xTable[, 5], 2)
      xTable[, 6]   <- round(xTable[, 6], 4)
      xTable        <- cbind(xTable, sigStars(xTable[, 6]))
      names(xTable) <- c('SS', 'MSS', 'nDF', 'dDF', 'F', 'P', 'Sig') 
    } else {
      xTable <- data.frame('######', 'No known model', '######')
      names(xTable) <- c('%%%', '***', '&&&')
    }
  } else {
    xTable <- data.frame('######', 'No known model', '######')
    names(xTable) <- c('%%%', '***', '&&&')
  }
  return(xTable)
}
```

# Introduction
The main aim with the next experiment (schemaVR3) is to show that recollection and familiarity  are differently associated with object/location expectancy, which has - as the two previous experiments showed - U-shaped relationship with object/location memory. Our underlying assumption is that both advantages are driven by different processes. 

Before I can pre-register the analysis of schemaVR3, I need to base it on a proper power analysis. To do this, I need to understand why I get different (i.e. opposite) results when I carry out a correlational analysis compared to a mixed linear approach similar to the models, which I use the main analysis.

# Preparation
Just loading and preparing the data here.

```{r}
# Loading 
load("U:/Projects/schemaVR/report_firstYear/report/data/exp2Data.RData")
dataSchemaVR2 <- combData
rm(combData)

#Add (non-)kitchen object factor to data
dataSchemaVR2$expectedInKitchen                                      <- 'non-kitchen'
dataSchemaVR2[which(dataSchemaVR2$objNum < 13), 'expectedInKitchen'] <- 'kitchen'

# Notes and decision on participants:
# Participant #20 to #24: Exclude participants because they did the  wrong objLocTargetRating
dataSchemaVR2 <- subset(dataSchemaVR2, subNum >= 25)
# Participant #20 to #27: Foil2 for umbrella was not saved.
# Participant #25 to #27: Rated object 16 at location 1 instead of 14. This value is therefore missing.
# Participant #22: Seen objects twice but is excluded anyway. 
# Participant #26: Check recall microwave because it was correct (it is). The 2nd rating was 100 not 0.
dataSchemaVR2[which(dataSchemaVR2$subNum == 26 & dataSchemaVR2$objNum == 3), 'generalRatingPost'] <- 100

# Response given for judgement (0 = no memory, 1 = remember, 2 = familiar, 3 = guess)
dataSchemaVR2$recallMemory[which(dataSchemaVR2$recallMemory == -1)] <- NA # Code missing value
```

# Original analyses
This section contains the original analysis from my first year report. 

## Correlational analysis
```{r}
# Aggregating
schemaVR2_table4 <- ddply(dataSchemaVR2, 
                          c('objNum', 'objName'), 
                          summarise,
                          objLocTargetRating = mean(objLocTargetRating, na.rm = TRUE),
                          RecallNoMemory     = table(recallMemory)[1],
                          RecallRecollection = table(recallMemory)[2],
                          RecallFamiliarity  = table(recallMemory)[3],
                          RecallGuess        = table(recallMemory)[4],
                          RecallN            = sum(table(recallMemory)),
                          RecallRec_per      = (RecallRecollection/RecallN)*100,
                          RecallFam_per      = (RecallFamiliarity/RecallN)*100,
                          RecallFam_per_ind  = (RecallFamiliarity/(RecallN - RecallRecollection))*100,
                          RecallGuess_per    = (RecallGuess/(RecallN - RecallRecollection - RecallFamiliarity))*100,
                          AFCNoMemory        = table(resCon)[1], 
                          AFCRecollection    = table(resCon)[2],
                          AFCFamiliarity     = table(resCon)[3],
                          AFCGuess           = table(resCon)[4],
                          AFCN               = sum(table(resCon)),
                          AFCRec_per         = (AFCRecollection/AFCN)*100,
                          AFCFam_per         = (AFCFamiliarity/AFCN)*100,
                          AFCFam_per_ind     = (AFCFamiliarity/(AFCN - AFCRecollection))*100,
                          AFCGuess_per       = (AFCGuess/(AFCN - AFCRecollection - AFCFamiliarity))*100)

####################################
# Correlation
# Recall
recall_cor1 <- cor.test( ~ RecallRec_per + objLocTargetRating, schemaVR2_table4)
recall_cor2 <- cor.test( ~ RecallFam_per + objLocTargetRating, schemaVR2_table4)
recall_cor3 <- cor.test( ~ RecallFam_per_ind + objLocTargetRating, schemaVR2_table4)
recall_cor4 <- cor.test( ~ RecallGuess_per + objLocTargetRating, schemaVR2_table4)

# AFC
afc_cor1   <- cor.test( ~ AFCRec_per + objLocTargetRating, schemaVR2_table4)
afc_cor2   <- cor.test( ~ AFCFam_per + objLocTargetRating, schemaVR2_table4)
afc_cor3   <- cor.test( ~ AFCFam_per_ind + objLocTargetRating, schemaVR2_table4)
afc_cor4   <- cor.test( ~ AFCGuess_per+ objLocTargetRating, schemaVR2_table4)

####################################
# Plotting
# Recall
corPlot1 <- ggplot(schemaVR2_table4, aes(x = objLocTargetRating, y = RecallRec_per)) +
  geom_point() + 
  geom_smooth(method = 'lm') +
  labs(y = 'Precentage of response in recall task',
       x = '',
       title = 'Recollection') +
  annotate("text", 
           x = 0, 
           y = 87.5, 
           label = paste('r ', 
                         rValue(recall_cor1$estimate),
                         ', p ', 
                         pValue(recall_cor1$p.value), 
                         sep = '')) +
  coord_cartesian(xlim = c(-100, 100), 
                  ylim = c(0, 100), 
                  expand = FALSE) + 
  theme(plot.margin = unit(c(0, 0.5, 0, 0), "lines"))

corPlot2 <- ggplot(schemaVR2_table4, aes(x = objLocTargetRating, y = RecallFam_per)) +
  geom_point() + 
  geom_smooth(method = 'lm') +
  labs(y = '',
       x = '',
       title = 'Familiarity') +
  annotate("text", 
           x = 0, 
           y = 87.5, 
           label = paste('r ', 
                         rValue(recall_cor2$estimate),
                         ', p ', 
                         pValue(recall_cor2$p.value), 
                         sep = '')) +
  coord_cartesian(xlim = c(-100, 100), 
                  ylim = c(0, 100), 
                  expand = FALSE) + 
  theme(plot.margin = unit(c(0, 0.5, 0, 0), "lines"))

corPlot3 <- ggplot(schemaVR2_table4, aes(x = objLocTargetRating, y = RecallFam_per_ind)) +
  geom_point() + 
  geom_smooth(method = 'lm') +
  labs(y = '',
       x = '',
       title = 'Familiarity (independent)') +
  annotate("text", 
           x = 0, 
           y = 87.5, 
           label = paste('r ', 
                         rValue(recall_cor3$estimate),
                         ', p ', 
                         pValue(recall_cor3$p.value), 
                         sep = '')) +
  coord_cartesian(xlim = c(-100, 100), 
                  ylim = c(0, 100), 
                  expand = FALSE) + 
  theme(plot.margin = unit(c(0, 0.5, 0, 0), "lines"))

corPlot4 <- ggplot(schemaVR2_table4, aes(x = objLocTargetRating, y = RecallGuess_per)) +
  geom_point() + 
  geom_smooth(method = 'lm') +
  labs(y = '',
       x = '',
       title = 'Guess') +
  annotate("text", 
           x = 0, 
           y = 87.5, 
           label = paste('r ', 
                         rValue(recall_cor4$estimate),
                         ', p ', 
                         pValue(recall_cor4$p.value), 
                         sep = '')) +
  coord_cartesian(xlim = c(-100, 100), 
                  ylim = c(0, 100), 
                  expand = FALSE) + 
  theme(plot.margin = unit(c(0, 0.5, 0, 0), "lines"))

# AFC
corPlot5 <- ggplot(schemaVR2_table4, aes(x = objLocTargetRating, y = AFCRec_per)) +
  geom_point() + 
  geom_smooth(method = 'lm') +
  labs(y = 'Precentage of response in 3AFC task',  
       x = "Object/location expectancy") +
  annotate("text", 
           x = 0, 
           y = 87.5, 
           label = paste('r ', 
                         rValue(afc_cor1$estimate),
                         ', p ', 
                         pValue(afc_cor1$p.value), 
                         sep = '')) +
  coord_cartesian(xlim = c(-100, 100), 
                  ylim = c(0, 100), 
                  expand = FALSE) + 
  theme(plot.margin = unit(c(0, 0.5, 0, 0), "lines"))

corPlot6 <- ggplot(schemaVR2_table4, aes(x = objLocTargetRating, y = AFCFam_per)) +
  geom_point() + 
  geom_smooth(method = 'lm') +
  labs(y = '',  
       x = "Object/location expectancy") +
  annotate("text", 
           x = 0, 
           y = 87.5, 
           label = paste('r ', 
                         rValue(afc_cor2$estimate),
                         ', p ', 
                         pValue(afc_cor2$p.value), 
                         sep = '')) +
  coord_cartesian(xlim = c(-100, 100), 
                  ylim = c(0, 100), 
                  expand = FALSE) + 
  theme(plot.margin = unit(c(0, 0.5, 0, 0), "lines"))

corPlot7 <- ggplot(schemaVR2_table4, aes(x = objLocTargetRating, y = AFCFam_per_ind)) +
  geom_point() + 
  geom_smooth(method = 'lm') +
  labs(y = '',  
       x = "Object/location expectancy") +
  annotate("text", 
           x = 0, 
           y = 87.5, 
           label = paste('r ', 
                         rValue(afc_cor3$estimate),
                         ', p ', 
                         pValue(afc_cor3$p.value),
                         sep = '')) +
  coord_cartesian(xlim = c(-100, 100), 
                  ylim = c(0, 100), 
                  expand = FALSE) + 
  theme(plot.margin = unit(c(0, 0.5, 0, 0), "lines"))

corPlot8 <- ggplot(schemaVR2_table4, aes(x = objLocTargetRating, y = AFCGuess_per)) +
  geom_point() + 
  geom_smooth(method = 'lm') +
  labs(y = '',  
       x = "Object/location expectancy") +
  annotate("text", 
           x = 0, 
           y = 25, 
           label = paste('r ', 
                         rValue(afc_cor4$estimate),
                         ', p ', 
                         pValue(afc_cor4$p.value), 
                         sep = '')) +
  coord_cartesian(xlim = c(-100, 100), 
                  ylim = c(0, 100), 
                  expand = FALSE) + 
  theme(plot.margin = unit(c(0, 0.5, 0, 0), "lines"))


corPlot <- grid.arrange(corPlot1,
                        corPlot2,
                        corPlot3,
                        corPlot4,
                        corPlot5,
                        corPlot6,
                        corPlot7,
                        corPlot8,
                        ncol = 4, 
                        nrow = 2)

## Figure: The figure above shows 4 scatter plots created by ggplot2 arranged into one panel. 
```

As can be seen above, there is evidence that incidence of recollection is higher for lower values of object/location expectancy for the 3AFC task. It is not surprising to only find this in the 3AFC task and not in the recall task because traditionally this distinction is applied to recognition and not location recall anyway. Interestingly though, there is a significant correlation for guess responses in the recall task and object/location expectancy corrobrating our initial suspicion that participants might base their response on guesses when they can rely on schema (i.e. locations that are very expected).

The relationship between familiarity and object/location expectancy depends on way familiarity is coded. If just coded as the number of familiar responses divided by the number of total repsonses, the correlation is positive and close to significant. If calculated following Yonelinas' independence coding, then the correlation becomes less pronounced. 

## Mixed models
Preparing and recoding the data for mixed effects analysis.
```{r}
####################################
# Code for recollection, familiarity and guess
# Recollection
# Recall
recollectionRecall               <- rep(0, length(dataSchemaVR2$recallMemory))
recollectionRecall[dataSchemaVR2$recallMemory == 1]   <- 1
recollectionRecall[is.na(dataSchemaVR2$recallMemory)] <- NA
recollectionRecall               <- as.factor(recollectionRecall)
levels(recollectionRecall)       <- c('not recollected', 'recollected')
dataSchemaVR2$recollectionRecall <- recollectionRecall

# 3AFc
recollection3AFC               <- rep(0, length(dataSchemaVR2$resCon))
recollection3AFC[dataSchemaVR2$resCon == 1] <- 1
recollection3AFC[is.na(dataSchemaVR2$resCon)] <- NA
recollection3AFC               <- as.factor(recollection3AFC)
levels(recollection3AFC)       <- c('not recollected', 'recollected')
dataSchemaVR2$recollection3AFC <- recollection3AFC

####################################
# Familiarity
# Recall
familiarityRecall               <- rep(0, length(dataSchemaVR2$recallMemory))
familiarityRecall[dataSchemaVR2$recallMemory == 2]   <- 1
familiarityRecall[is.na(dataSchemaVR2$recallMemory)] <- NA
familiarityRecall               <- as.factor(familiarityRecall)
levels(familiarityRecall)       <- c('not familiar', 'familiar')
dataSchemaVR2$familiarityRecall <- familiarityRecall

# 3AFC
familiarity3AFC               <- rep(0, length(dataSchemaVR2$resCon))
familiarity3AFC[dataSchemaVR2$resCon == 2]   <- 1
familiarity3AFC[is.na(dataSchemaVR2$resCon)] <- NA
familiarity3AFC               <- as.factor(familiarity3AFC)
levels(familiarity3AFC)       <- c('not familiar', 'familiar')
dataSchemaVR2$familiarity3AFC <- familiarity3AFC

####################################
# Guess
# Recall
guessRecall               <- rep(0, length(dataSchemaVR2$recallMemory))
guessRecall[dataSchemaVR2$recallMemory == 3]   <- 1
guessRecall[is.na(dataSchemaVR2$recallMemory)] <- NA
guessRecall               <- as.factor(guessRecall)
levels(guessRecall)       <- c('not guessed', 'guessed')
dataSchemaVR2$guessRecall <- guessRecall

# 3AFC
guess3AFC               <- rep(0, length(dataSchemaVR2$resCon))
guess3AFC[dataSchemaVR2$resCon == 3]   <- 1
guess3AFC[is.na(dataSchemaVR2$resCon)] <- NA
guess3AFC               <- as.factor(guess3AFC)
levels(guess3AFC)       <- c('not guessed', 'guessed')
dataSchemaVR2$guess3AFC <- guess3AFC
```

In the models below, I model every response (present vs. not present) for each trial as a function of object/location memory corrected for the objects' general expectancy. As random effects, intercept for each object and for participants are added. Note that the indenpendent variables are standardised (centered and scaled by SD). 
```{r}
####################################
# Models
# Recollection
# Recall
schemaVR2_rf_model1 <- glmer(recollectionRecall ~  scale(objLocTargetRating)  +
                             scale(generalRatingPost) +
                             (1 | subNum) +
                             (1 | objNum), 
                           data = dataSchemaVR2,
                           family = binomial,
                           control = glmerControl(optimizer = "bobyqa"),
                           nAGQ = 1)

createResultTable(schemaVR2_rf_model1)

# 3AFC
schemaVR2_rf_model2 <- glmer(recollection3AFC ~  scale(objLocTargetRating) +
                             scale(generalRatingPost) +
                             (1 | subNum) +
                             (1 | objNum), 
                           data = dataSchemaVR2,
                           family = binomial,
                           control = glmerControl(optimizer = "bobyqa"),
                           nAGQ = 1)

createResultTable(schemaVR2_rf_model2)
```

As can be seen above, for both the recall task and the 3AFC task we have postive relationship between object/location expectancy and recolllection when general expectancy is controlled for. This is in stark contrast with results from the correlational analysis. 

For the sake of completeness, see below for the other models.

```{r}
####################################
# Familairity
# Recall
schemaVR2_rf_model3 <- glmer(familiarityRecall ~  objLocTargetRating  +
                             generalRatingPost +
                             (1 | subNum) +
                             (1 | objNum), 
                           data = dataSchemaVR2,
                           family = binomial,
                           control = glmerControl(optimizer = "bobyqa"),
                           nAGQ = 1)

createResultTable(schemaVR2_rf_model3)

# 3AFc
schemaVR2_rf_model4 <- glmer(familiarity3AFC ~  objLocTargetRating  +
                             generalRatingPost +
                             (1 | subNum) +
                             (1 | objNum), 
                           data = dataSchemaVR2,
                           family = binomial,
                           control = glmerControl(optimizer = "bobyqa"),
                           nAGQ = 1)

createResultTable(schemaVR2_rf_model4)
####################################
# Guess
schemaVR2_rf_model5 <- glmer(guessRecall ~  objLocTargetRating  +
                             generalRatingPost ++
                             (1 | subNum) +
                             (1 | objNum), 
                           data = dataSchemaVR2,
                           family = binomial,
                           control = glmerControl(optimizer = "bobyqa"),
                           nAGQ = 1)

createResultTable(schemaVR2_rf_model5)

# 3AFc
schemaVR2_rf_model6 <- glmer(guess3AFC ~  objLocTargetRating  +
                             generalRatingPost +  
                             (1 | subNum) +
                             (1 | objNum), 
                           data = dataSchemaVR2,
                           family = binomial,
                           control = glmerControl(optimizer = "bobyqa"),
                           nAGQ = 1)

createResultTable(schemaVR2_rf_model6)
```

# Understanding the disparity
Here, I try to understand the disparity between the correlational analysis and the result of the mixed models analysis by exploring and visualising the data.

## Aggregate by recollection 
To do this, I compare the average expectancy when a participant gave a remember response versus any other response. The problem with this approach might be that this includes all the other responses (no memory, guess and familiar). I do the same for objects, so comparing the average expectancy when an object's location was recollected. The motivation was to see whether a Simpson's paradox situation might drive our results. 

```{r}
####################################
# Recall
# Across subjects
recAgg_recall_sub  <- ddply(na.omit(dataSchemaVR2), 
                            c('subNum','recollectionRecall'), 
                            summarise, 
                            objLocTargetRating = mean(objLocTargetRating, na.rm = TRUE))


recAgg_recall_sub_plot <- ggplot(recAgg_recall_sub, 
                                 aes(x = recollectionRecall, y = objLocTargetRating)) +
  geom_boxplot(width = 0.5) +
  geom_point() +  
  geom_line(aes(group = subNum)) +
  labs(title = 'Recall task for each sub',
       y = 'Object/location expectancy',  
       x = "Recollection")

# Across objects
recAgg_recall_obj  <- ddply(na.omit(dataSchemaVR2), 
                            c('objNum','recollectionRecall'), 
                            summarise, 
                            objLocTargetRating = mean(objLocTargetRating, na.rm = TRUE))


recAgg_recall_obj_plot <- ggplot(recAgg_recall_obj, 
                                 aes(x = recollectionRecall, y = objLocTargetRating)) +
  geom_boxplot(width = 0.5) +
  geom_point() +  
  geom_line(aes(group = objNum)) +
  labs(title = 'Recall task for each obj',
       y = 'Object/location expectancy',  
       x = "Recollection")

# Plot both
recAgg_recall_plot <- grid.arrange(recAgg_recall_sub_plot,
                        recAgg_recall_obj_plot,
                        ncol = 2)

## Figure: This plot was created with ggplot2. Both plots in the panel show a boxplot for a factor with two levels where the individual datapoints are included and connected across the measuring unit to indicate the intra-unit change across the factor, which is either subjects or objects.  

# Test both effects
t.test(objLocTargetRating ~ recollectionRecall, recAgg_recall_sub)
t.test(objLocTargetRating ~ recollectionRecall, recAgg_recall_obj)
```
For the recall task, both aggregations show the same pattern, which is recollection is associated with higher expectancy values, which is also the opposite of what the correlational analsyis showed. 

```{r}
####################################
# 3AFC
# Across subjects
recAgg_AFC_sub  <- ddply(na.omit(dataSchemaVR2), 
                            c('subNum','recollection3AFC'), 
                            summarise, 
                            objLocTargetRating = mean(objLocTargetRating, na.rm = TRUE))


recAgg_AFC_sub_plot <- ggplot(recAgg_AFC_sub, 
                              aes(x = recollection3AFC, y = objLocTargetRating)) +
  geom_boxplot(width = 0.5) +
  geom_point() +  
  geom_line(aes(group = subNum)) +
  labs(title = '3AFC task for each sub',
       y = 'Object/location expectancy',  
       x = "Recollection")

# Across objects
recAgg_AFC_obj  <- ddply(na.omit(dataSchemaVR2), 
                            c('objNum','recollection3AFC'), 
                            summarise, 
                            objLocTargetRating = mean(objLocTargetRating, na.rm = TRUE))


recAgg_AFC_obj_plot <- ggplot(recAgg_AFC_obj, 
                              aes(x = recollection3AFC, y = objLocTargetRating)) +
  geom_boxplot(width = 0.5) +
  geom_point() +  
  geom_line(aes(group = objNum)) +
  labs(title = '3AFC task for each obj',
       y = 'Object/location expectancy',  
       x = "Recollection")


# Plot both
recAgg_AFC_plot <- grid.arrange(recAgg_AFC_sub_plot,
                        recAgg_AFC_obj_plot,
                        ncol = 2)

## Figure: This plot was created with ggplot2. Both plots in the panel show a boxplot for a factor with two levels where the individual datapoints are included and connected across the measuring unit to indicate the intra-unit change across the factor, which is either subjects or objects.  

# Test both effects
t.test(objLocTargetRating ~ recollection3AFC, recAgg_AFC_sub)
t.test(objLocTargetRating ~ recollection3AFC, recAgg_AFC_obj)
```
For the 3AFC task, it looks different when aggregated by subjects and objects. Interestingly, the subject approach looks similar to the correlational analysis. It is puzzling that aggregating by objects gives a different result than the correlational analysis because the correlational is also based on objects. 

## Analysis based only on correct responses
Another idea is that maybe, the problem is incorrect responses influence the results giving rise to this disparity.  

### Mixed models 
```{r}
####################################
# Models
# Recollection
# Recall
schemaVR2_rf_model7 <- glmer(recollectionRecall ~  scale(objLocTargetRating)  +
                             scale(generalRatingPost) +
                             (1 | subNum) +
                             (1 | objNum), 
                           data = subset(dataSchemaVR2, dataSchemaVR2$accRecall == 1),
                           family = binomial,
                           control = glmerControl(optimizer = "bobyqa"),
                           nAGQ = 1)

createResultTable(schemaVR2_rf_model7)

# 3AFC
schemaVR2_rf_model8 <- glmer(recollection3AFC ~  scale(objLocTargetRating)  +
                             scale(generalRatingPost) +
                             (1 | subNum) +
                             (1 | objNum), 
                           data = subset(dataSchemaVR2, dataSchemaVR2$accAFC == 1),
                           family = binomial,
                           control = glmerControl(optimizer = "bobyqa"),
                           nAGQ = 1)

createResultTable(schemaVR2_rf_model8)
```

As can be seen above, it doesn't change the results of the 3AFC model.

### Correlational analsysis
```{r}
# Aggregating
data_corr_AFC_correctOnly <- ddply(subset(dataSchemaVR2, dataSchemaVR2$accAFC == 1),
                                   c('objNum', 'objName'), 
                                   summarise,
                                   objLocTargetRating = mean(objLocTargetRating, na.rm = TRUE),
                                   AFCNoMemory        = table(resCon)[1], 
                                   AFCRecollection    = table(resCon)[2],
                                   AFCFamiliarity     = table(resCon)[3],
                                   AFCGuess           = table(resCon)[4],
                                   AFCN               = sum(table(resCon)),
                                   AFCRec_per         = (AFCRecollection/AFCN)*100,
                                   AFCFam_per         = (AFCFamiliarity/AFCN)*100,
                                   AFCFam_per_ind     = (AFCFamiliarity/(AFCN - AFCRecollection))*100,
                                   AFCGuess_per       = (AFCGuess/(AFCN - AFCRecollection - AFCFamiliarity))*100)
 
data_corr_recall_correctOnly <- ddply(subset(dataSchemaVR2, dataSchemaVR2$accRecall == 1),
                                      c('objNum', 'objName'), 
                                      summarise,
                                      objLocTargetRating = mean(objLocTargetRating, na.rm = TRUE),
                                      RecallNoMemory     = table(recallMemory)[1],
                                      RecallRecollection = table(recallMemory)[2],
                                      RecallFamiliarity  = table(recallMemory)[3],
                                      RecallGuess        = table(recallMemory)[4],
                                      RecallN            = sum(table(recallMemory)),
                                      RecallRec_per      = (RecallRecollection/RecallN)*100,
                                      RecallFam_per      = (RecallFamiliarity/RecallN)*100,
                                      RecallFam_per_ind  = (RecallFamiliarity/(RecallN - RecallRecollection))*100,
                                      RecallGuess_per    = (RecallGuess/(RecallN - RecallRecollection - RecallFamiliarity))*100)

####################################
# Correlation
# Recall
recall_cor1 <- cor.test( ~ RecallRec_per + objLocTargetRating, data_corr_recall_correctOnly)
recall_cor2 <- cor.test( ~ RecallFam_per + objLocTargetRating, data_corr_recall_correctOnly)
recall_cor3 <- cor.test( ~ RecallFam_per_ind + objLocTargetRating, data_corr_recall_correctOnly)

# AFC
afc_cor1   <- cor.test( ~ AFCRec_per + objLocTargetRating, data_corr_AFC_correctOnly)
afc_cor2   <- cor.test( ~ AFCFam_per + objLocTargetRating, data_corr_AFC_correctOnly)
afc_cor3   <- cor.test( ~ AFCFam_per_ind + objLocTargetRating, data_corr_AFC_correctOnly)

####################################
# Plotting
# Recall
corPlot1 <- ggplot(data_corr_recall_correctOnly, aes(x = objLocTargetRating, y = RecallRec_per)) +
  geom_point() + 
  geom_smooth(method = 'lm') +
  labs(y = 'Precentage of response in recall task',
       x = '',
       title = 'Recollection') +
  annotate("text", 
           x = 0, 
           y = 87.5, 
           label = paste('r ', 
                         rValue(recall_cor1$estimate),
                         ', p ', 
                         pValue(recall_cor1$p.value), 
                         sep = '')) +
  coord_cartesian(xlim = c(-100, 100), 
                  ylim = c(0, 100), 
                  expand = FALSE) + 
  theme(plot.margin = unit(c(0, 0.5, 0, 0), "lines"))

corPlot2 <- ggplot(data_corr_recall_correctOnly, aes(x = objLocTargetRating, y = RecallFam_per)) +
  geom_point() + 
  geom_smooth(method = 'lm') +
  labs(y = '',
       x = '',
       title = 'Familiarity') +
  annotate("text", 
           x = 0, 
           y = 87.5, 
           label = paste('r ', 
                         rValue(recall_cor2$estimate),
                         ', p ', 
                         pValue(recall_cor2$p.value), 
                         sep = '')) +
  coord_cartesian(xlim = c(-100, 100), 
                  ylim = c(0, 100), 
                  expand = FALSE) + 
  theme(plot.margin = unit(c(0, 0.5, 0, 0), "lines"))

corPlot3 <- ggplot(data_corr_recall_correctOnly, aes(x = objLocTargetRating, y = RecallFam_per_ind)) +
  geom_point() + 
  geom_smooth(method = 'lm') +
  labs(y = '',
       x = '',
       title = 'Familiarity (independent)') +
  annotate("text", 
           x = 0, 
           y = 87.5, 
           label = paste('r ', 
                         rValue(recall_cor3$estimate),
                         ', p ', 
                         pValue(recall_cor3$p.value), 
                         sep = '')) +
  coord_cartesian(xlim = c(-100, 100), 
                  ylim = c(0, 100), 
                  expand = FALSE) + 
  theme(plot.margin = unit(c(0, 0.5, 0, 0), "lines"))


# AFC
corPlot5 <- ggplot(data_corr_AFC_correctOnly, aes(x = objLocTargetRating, y = AFCRec_per)) +
  geom_point() + 
  geom_smooth(method = 'lm') +
  labs(y = 'Precentage of response in 3AFC task',  
       x = "Object/location expectancy") +
  annotate("text", 
           x = 0, 
           y = 87.5, 
           label = paste('r ', 
                         rValue(afc_cor1$estimate),
                         ', p ', 
                         pValue(afc_cor1$p.value), 
                         sep = '')) +
  coord_cartesian(xlim = c(-100, 100), 
                  ylim = c(0, 100), 
                  expand = FALSE) + 
  theme(plot.margin = unit(c(0, 0.5, 0, 0), "lines"))

corPlot6 <- ggplot(data_corr_AFC_correctOnly, aes(x = objLocTargetRating, y = AFCFam_per)) +
  geom_point() + 
  geom_smooth(method = 'lm') +
  labs(y = '',  
       x = "Object/location expectancy") +
  annotate("text", 
           x = 0, 
           y = 87.5, 
           label = paste('r ', 
                         rValue(afc_cor2$estimate),
                         ', p ', 
                         pValue(afc_cor2$p.value), 
                         sep = '')) +
  coord_cartesian(xlim = c(-100, 100), 
                  ylim = c(0, 100), 
                  expand = FALSE) + 
  theme(plot.margin = unit(c(0, 0.5, 0, 0), "lines"))

corPlot7 <- ggplot(data_corr_AFC_correctOnly, aes(x = objLocTargetRating, y = AFCFam_per_ind)) +
  geom_point() + 
  geom_smooth(method = 'lm') +
  labs(y = '',  
       x = "Object/location expectancy") +
  annotate("text", 
           x = 0, 
           y = 87.5, 
           label = paste('r ', 
                         rValue(afc_cor3$estimate),
                         ', p ', 
                         pValue(afc_cor3$p.value),
                         sep = '')) +
  coord_cartesian(xlim = c(-100, 100), 
                  ylim = c(0, 100), 
                  expand = FALSE) + 
  theme(plot.margin = unit(c(0, 0.5, 0, 0), "lines"))




corPlot <- grid.arrange(corPlot1,
                        corPlot2,
                        corPlot3,
                        corPlot5,
                        corPlot6,
                        corPlot7,
                        ncol = 3, 
                        nrow = 2)

## Figure: The figure above shows 4 scatter plots created by ggplot2 arranged into one panel. 
```
However only including correct responses changes the strength thought not the pattern of the correlations.

# Analysing only kitchen item
Another idea, we had was to limit the analysis to kitchen objects to reduce the influence of the fact that non-kitchen objects a) vary greatly in their general expectancy and b) in terms of their object/location expectancy. 

## Correlation
```{r}
# Aggregating
schemaVR2_table4 <- ddply(subset(dataSchemaVR2, dataSchemaVR2$expectedInKitchen == 'kitchen'), 
                          c('objNum', 'objName'), 
                          summarise,
                          objLocTargetRating = mean(objLocTargetRating, na.rm = TRUE),
                          RecallNoMemory     = table(recallMemory)[1],
                          RecallRecollection = table(recallMemory)[2],
                          RecallFamiliarity  = table(recallMemory)[3],
                          RecallGuess        = table(recallMemory)[4],
                          RecallN            = sum(table(recallMemory)),
                          RecallRec_per      = (RecallRecollection/RecallN)*100,
                          RecallFam_per      = (RecallFamiliarity/RecallN)*100,
                          RecallFam_per_ind  = (RecallFamiliarity/(RecallN - RecallRecollection))*100,
                          RecallGuess_per    = (RecallGuess/(RecallN - RecallRecollection - RecallFamiliarity))*100,
                          AFCNoMemory        = table(resCon)[1], 
                          AFCRecollection    = table(resCon)[2],
                          AFCFamiliarity     = table(resCon)[3],
                          AFCGuess           = table(resCon)[4],
                          AFCN               = sum(table(resCon)),
                          AFCRec_per         = (AFCRecollection/AFCN)*100,
                          AFCFam_per         = (AFCFamiliarity/AFCN)*100,
                          AFCFam_per_ind     = (AFCFamiliarity/(AFCN - AFCRecollection))*100,
                          AFCGuess_per       = (AFCGuess/(AFCN - AFCRecollection - AFCFamiliarity))*100)

####################################
# Correlation
# Recall
recall_cor1 <- cor.test( ~ RecallRec_per + objLocTargetRating, schemaVR2_table4)
recall_cor2 <- cor.test( ~ RecallFam_per + objLocTargetRating, schemaVR2_table4)
recall_cor3 <- cor.test( ~ RecallFam_per_ind + objLocTargetRating, schemaVR2_table4)
recall_cor4 <- cor.test( ~ RecallGuess_per + objLocTargetRating, schemaVR2_table4)

# AFC
afc_cor1   <- cor.test( ~ AFCRec_per + objLocTargetRating, schemaVR2_table4)
afc_cor2   <- cor.test( ~ AFCFam_per + objLocTargetRating, schemaVR2_table4)
afc_cor3   <- cor.test( ~ AFCFam_per_ind + objLocTargetRating, schemaVR2_table4)
afc_cor4   <- cor.test( ~ AFCGuess_per+ objLocTargetRating, schemaVR2_table4)

####################################
# Plotting
# Recall
corPlot1 <- ggplot(schemaVR2_table4, aes(x = objLocTargetRating, y = RecallRec_per)) +
  geom_point() + 
  geom_smooth(method = 'lm') +
  labs(y = 'Precentage of response in recall task',
       x = '',
       title = 'Recollection') +
  annotate("text", 
           x = 0, 
           y = 87.5, 
           label = paste('r ', 
                         rValue(recall_cor1$estimate),
                         ', p ', 
                         pValue(recall_cor1$p.value), 
                         sep = '')) +
  coord_cartesian(xlim = c(-100, 100), 
                  ylim = c(0, 100), 
                  expand = FALSE) + 
  theme(plot.margin = unit(c(0, 0.5, 0, 0), "lines"))

corPlot2 <- ggplot(schemaVR2_table4, aes(x = objLocTargetRating, y = RecallFam_per)) +
  geom_point() + 
  geom_smooth(method = 'lm') +
  labs(y = '',
       x = '',
       title = 'Familiarity') +
  annotate("text", 
           x = 0, 
           y = 87.5, 
           label = paste('r ', 
                         rValue(recall_cor2$estimate),
                         ', p ', 
                         pValue(recall_cor2$p.value), 
                         sep = '')) +
  coord_cartesian(xlim = c(-100, 100), 
                  ylim = c(0, 100), 
                  expand = FALSE) + 
  theme(plot.margin = unit(c(0, 0.5, 0, 0), "lines"))

corPlot3 <- ggplot(schemaVR2_table4, aes(x = objLocTargetRating, y = RecallFam_per_ind)) +
  geom_point() + 
  geom_smooth(method = 'lm') +
  labs(y = '',
       x = '',
       title = 'Familiarity (independent)') +
  annotate("text", 
           x = 0, 
           y = 87.5, 
           label = paste('r ', 
                         rValue(recall_cor3$estimate),
                         ', p ', 
                         pValue(recall_cor3$p.value), 
                         sep = '')) +
  coord_cartesian(xlim = c(-100, 100), 
                  ylim = c(0, 100), 
                  expand = FALSE) + 
  theme(plot.margin = unit(c(0, 0.5, 0, 0), "lines"))

corPlot4 <- ggplot(schemaVR2_table4, aes(x = objLocTargetRating, y = RecallGuess_per)) +
  geom_point() + 
  geom_smooth(method = 'lm') +
  labs(y = '',
       x = '',
       title = 'Guess') +
  annotate("text", 
           x = 0, 
           y = 87.5, 
           label = paste('r ', 
                         rValue(recall_cor4$estimate),
                         ', p ', 
                         pValue(recall_cor4$p.value), 
                         sep = '')) +
  coord_cartesian(xlim = c(-100, 100), 
                  ylim = c(0, 100), 
                  expand = FALSE) + 
  theme(plot.margin = unit(c(0, 0.5, 0, 0), "lines"))

# AFC
corPlot5 <- ggplot(schemaVR2_table4, aes(x = objLocTargetRating, y = AFCRec_per)) +
  geom_point() + 
  geom_smooth(method = 'lm') +
  labs(y = 'Precentage of response in 3AFC task',  
       x = "Object/location expectancy") +
  annotate("text", 
           x = 0, 
           y = 87.5, 
           label = paste('r ', 
                         rValue(afc_cor1$estimate),
                         ', p ', 
                         pValue(afc_cor1$p.value), 
                         sep = '')) +
  coord_cartesian(xlim = c(-100, 100), 
                  ylim = c(0, 100), 
                  expand = FALSE) + 
  theme(plot.margin = unit(c(0, 0.5, 0, 0), "lines"))

corPlot6 <- ggplot(schemaVR2_table4, aes(x = objLocTargetRating, y = AFCFam_per)) +
  geom_point() + 
  geom_smooth(method = 'lm') +
  labs(y = '',  
       x = "Object/location expectancy") +
  annotate("text", 
           x = 0, 
           y = 87.5, 
           label = paste('r ', 
                         rValue(afc_cor2$estimate),
                         ', p ', 
                         pValue(afc_cor2$p.value), 
                         sep = '')) +
  coord_cartesian(xlim = c(-100, 100), 
                  ylim = c(0, 100), 
                  expand = FALSE) + 
  theme(plot.margin = unit(c(0, 0.5, 0, 0), "lines"))

corPlot7 <- ggplot(schemaVR2_table4, aes(x = objLocTargetRating, y = AFCFam_per_ind)) +
  geom_point() + 
  geom_smooth(method = 'lm') +
  labs(y = '',  
       x = "Object/location expectancy") +
  annotate("text", 
           x = 0, 
           y = 87.5, 
           label = paste('r ', 
                         rValue(afc_cor3$estimate),
                         ', p ', 
                         pValue(afc_cor3$p.value),
                         sep = '')) +
  coord_cartesian(xlim = c(-100, 100), 
                  ylim = c(0, 100), 
                  expand = FALSE) + 
  theme(plot.margin = unit(c(0, 0.5, 0, 0), "lines"))

corPlot8 <- ggplot(schemaVR2_table4, aes(x = objLocTargetRating, y = AFCGuess_per)) +
  geom_point() + 
  geom_smooth(method = 'lm') +
  labs(y = '',  
       x = "Object/location expectancy") +
  annotate("text", 
           x = 0, 
           y = 25, 
           label = paste('r ', 
                         rValue(afc_cor4$estimate),
                         ', p ', 
                         pValue(afc_cor4$p.value), 
                         sep = '')) +
  coord_cartesian(xlim = c(-100, 100), 
                  ylim = c(0, 100), 
                  expand = FALSE) + 
  theme(plot.margin = unit(c(0, 0.5, 0, 0), "lines"))


corPlot <- grid.arrange(corPlot1,
                        corPlot2,
                        corPlot3,
                        corPlot4,
                        corPlot5,
                        corPlot6,
                        corPlot7,
                        corPlot8,
                        ncol = 4, 
                        nrow = 2)

## Figure: The figure above shows 4 scatter plots created by ggplot2 arranged into one panel. 
```

Interestingly, even though 8 from 20 data points are removed form the analysis, the pattern in the correlational analysis got even more pronounced. Note that the relationship for the recall task now is basically completely absent except for the relationship for guess responses.

All in all, it seems as if non-kitchen items only add noise. 

## Mixed models
```{r}
####################################
# Models
# Recollection
# Recall
schemaVR2_rf_model7 <- glmer(recollectionRecall ~  scale(objLocTargetRating)  +
                             (1 | subNum) +
                             (1 | objNum), 
                           data = subset(dataSchemaVR2, dataSchemaVR2$expectedInKitchen == 'kitchen'),
                           family = binomial,
                           control = glmerControl(optimizer = "bobyqa"),
                           nAGQ = 1)

createResultTable(schemaVR2_rf_model7)

# 3AFC
schemaVR2_rf_model8 <- glmer(recollection3AFC ~  scale(objLocTargetRating)  +
                             (1 | subNum) +
                             (1 | objNum), 
                           data = subset(dataSchemaVR2, dataSchemaVR2$expectedInKitchen == 'kitchen'),
                           family = binomial,
                           control = glmerControl(optimizer = "bobyqa"),
                           nAGQ = 1)

createResultTable(schemaVR2_rf_model8)
```

While there is still a positive relationship for the recall task, the crucial 3AFC has a non-significant negative relationship, which now is in accordance with the correlational analysis. Therefore, I will explore howmany participants would be need to find such an effect.

# Power analysis
## Running the analysis
The power analysis was run with a script so that the time consuming analysis doesn't need to be repeated. That is the code of the script (for N = 500):

```{r eval = FALSE}
####################################
# Libraries
library(lmerTest)
library(simr)
# Green, Peter, and Catriona J. Macleod. 2016. âSIMR: An R package for power analysis of generalized linear mixed models by simulation.â Methods in Ecology and Evolution 7 (4): 493â98. doi:10.1111/2041-210X.12504.

####################################
# Loading and preparing data
load("U:/Projects/schemaVR/report_firstYear/report/data/exp2Data.RData")
dataSchemaVR2 <- combData
rm(combData)

#Add (non-)kitchen object factor to data
dataSchemaVR2$expectedInKitchen                                      <- 'non-kitchen'
dataSchemaVR2[which(dataSchemaVR2$objNum < 13), 'expectedInKitchen'] <- 'kitchen'

# Notes and decision on participants:
# Participant #20 to #24: Exclude participants because they did the  wrong objLocTargetRating
dataSchemaVR2 <- subset(dataSchemaVR2, subNum >= 25)
# Participant #20 to #27: Foil2 for umbrella was not saved.
# Participant #25 to #27: Rated object 16 at location 1 instead of 14. This value is therefore missing.
# Participant #22: Seen objects twice but is excluded anyway. 
# Participant #26: Check recall microwave because it was correct (it is). The 2nd rating was 100 not 0.
dataSchemaVR2[which(dataSchemaVR2$subNum == 26 & dataSchemaVR2$objNum == 3), 'generalRatingPost'] <- 100

# Response given for judgement (0 = no memory, 1 = remember, 2 = familiar, 3 = guess)
dataSchemaVR2$recallMemory[which(dataSchemaVR2$recallMemory == -1)] <- NA # Code missing value

# Recoding 3AFc recollection
recollection3AFC               <- rep(0, length(dataSchemaVR2$resCon))
recollection3AFC[dataSchemaVR2$resCon == 1] <- 1
recollection3AFC[is.na(dataSchemaVR2$resCon)] <- NA
recollection3AFC               <- as.factor(recollection3AFC)
levels(recollection3AFC)       <- c('not recollected', 'recollected')
dataSchemaVR2$recollection3AFC <- recollection3AFC

####################################
# Model that I base my power analysis on schemaVR2_rf_model8
originalModel <- glmer(recollection3AFC ~  scale(objLocTargetRating)  +
                               (1 | subNum) +
                               (1 | objNum), 
                             data = subset(dataSchemaVR2, dataSchemaVR2$expectedInKitchen == 'kitchen'),
                             family = binomial,
                             control = glmerControl(optimizer = "bobyqa"),
                             nAGQ = 1)

####################################
# Power analysis
# Retrospective âobserved powerâ 
retroPower <- powerSim(originalModel,
                       test = fixed("scale(objLocTargetRating)", method = 'z'),
                       progress = TRUE)

# Calculating the power curve 
# Number of runs in monte-carlo simulation
simrOptions(nsim = 1000)

# Extent model to 25 participants to plot power curve
extendedModel <- extend(originalModel,
                              along = 'subNum',
                              n = 500)

pc1 <- powerCurve(extendedModel, 
                  test = fixed("scale(objLocTargetRating)", method = 'z'),
                  along = "subNum", 
                  progress = TRUE)

save(retroPower,
     pc1, 
     originalModel, 
     extendedModel, 
     file = paste("schemaVR3_poweAnalysisData_", format(Sys.time(), "%Y%m%d_%H%M%S"), ".RData", sep = ""))
```

## Results
### N = 50
```{r}
load("schemaVR3_poweAnalysisData_20180927_135526.RData")
plot(pc1)
```

### N = 500
```{r}
load("schemaVR3_poweAnalysisData_20180927_170639.RData")
plot(pc1)
```

# Conclusion
Even collecting 500 participants won't bring us close to 80% power. Therefore, we will base our power analysis on the correlations (see [here](https://jaquent.github.io/2018/1002_schemaVR3_powerAnalysis.html))